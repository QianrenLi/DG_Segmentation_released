{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo for project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 50165.10it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 50099.19it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 33227.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of new inputs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 33396.80it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 49866.89it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 33442.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of new inputs: 100\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002598A588848>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import load_dataset\n",
    "\n",
    "trainset, valset = load_dataset(train=True)\n",
    "testset = load_dataset(train=False)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "print(valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], dtype=torch.uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    # The data need to be normalized and unnormalized to keep the same\n",
    "    # img = img / 255\n",
    "    # img = img / 2 + 0.5     # unnormalize\n",
    "\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(valloader)\n",
    "images, targets, _ = next(dataiter)\n",
    "print(targets)\n",
    "\n",
    "temp_image = torchvision.utils.make_grid(images)\n",
    "\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "net = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 0.792\n",
      "[2,    20] loss: 0.184\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, target) in enumerate(trainloader):\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimizeo \n",
    "        # change the data to float type\n",
    "        outputs = net(inputs.to(torch.float32))\n",
    "        # print((outputs.shape))\n",
    "        # print(target.to(torch.float32).dtype)\n",
    "        loss = criterion(outputs, target.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dsc of test set: 0.9911849576050784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "net = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "dscs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, targets, names = data\n",
    "        \n",
    "        outputs = net(images.to(torch.float32))\n",
    "        \n",
    "        for idx, name in enumerate(names):\n",
    "            output_np = torch.argmax(outputs[idx], dim=0).cpu().numpy()\n",
    "            binary_output = np.array(output_np)\n",
    "            target_np = targets[idx].cpu().numpy().astype(np.uint8)\n",
    "            \n",
    "            target_1d = np.reshape(target_np, (-1, 1))\n",
    "            pred_1d = np.reshape(binary_output, (-1, 1))\n",
    "\n",
    "            accuracy = accuracy_score(target_1d, pred_1d)\n",
    "            dsc = f1_score(target_1d, pred_1d)\n",
    "            \n",
    "            dscs.append(dsc)\n",
    "\n",
    "dsc_test = np.mean(dscs)\n",
    "print('Dsc of test set:', dsc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1b9c7f2f57af8f07e064f2c72ed76cd3499c7b2fb82bb3d901b6e74555bba53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
