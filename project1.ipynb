{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo for project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import load_dataset\n",
    "\n",
    "trainset, valset = load_dataset(train=True,is_vert_flip = False,is_rotate = True,is_translate = True,is_color_jitter = False,is_DG=0)\n",
    "testset = load_dataset(train=False)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    # The data need to be normalized and unnormalized to keep the same\n",
    "    # img = img / 255\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, targets = next(dataiter)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print(names)\n",
    "for i in range(batch_size):\n",
    "    target_np = torch.argmax(targets[i], dim=0).cpu().numpy()\n",
    "    plt.subplot(1,batch_size,i+1)\n",
    "    \n",
    "    plt.imshow(target_np,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Domain generalization example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import domain_generization, load_dataset\n",
    "# trainset_temp, _ = load_dataset(train=True,is_vert_flip = True,is_rotate = True,is_translate = True,is_color_jitter = False,is_DG=False)\n",
    "trainset_temp, _ = load_dataset(train=True,is_vert_flip = False,is_rotate = False,is_translate = False,is_color_jitter = False,is_DG=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "original_image, _ = trainset_temp.__getitem__(0) # Use the first image in training set.\n",
    "original_image = original_image / 2 + 0.5\n",
    "original_image = original_image.numpy()\n",
    "scaling_factor = 0.03 # 替换低频区域所占大小\n",
    "ratio = 1 #替换区域中目标域图片的幅度比重 \n",
    "num_generalized=10\n",
    "# domains = ['domain1','domain2','domain3'] # 可选：'random'（默认随机选择domain）, 'domain1', 'domain2', 'domain3'.\n",
    "domains = [1,2,3] # 可选：'random'（默认随机选择domain）, 'domain1', 'domain2', 'domain3'.\n",
    "original_image_freq = np.fft.fftshift(np.fft.fft2(original_image,axes=(-2,-1)),axes=(-2,-1))\n",
    "original_image_freq = np.log(np.abs(original_image_freq))/np.max(np.log(np.abs(original_image_freq))) # log and normalize\n",
    "plt.figure(figsize=[4,2])\n",
    "plt.subplot(1,2,1), plt.imshow(np.transpose(original_image, (1, 2, 0))), plt.xlabel('Raw Image.')\n",
    "plt.subplot(1,2,2), plt.imshow(np.transpose(original_image_freq, (1, 2, 0))), plt.xlabel('Raw Image (frequency).')\n",
    "dg_outputs_domains = []\n",
    "for domain in domains:\n",
    "    dg_outputs, dg_fre_outputs= np.array(domain_generization(original_image,scaling_factor, ratio,num_generalized,domain)) # 输出是一个float, 因为计算傅里叶变换的时候应该用float提高精度\n",
    "    dg_outputs = np.real(dg_outputs)\n",
    "    fig, axs = plt.subplots(2, num_generalized, figsize=(2*num_generalized, 2*2), layout=\"constrained\")\n",
    "    for i in range(num_generalized):\n",
    "        dg_output = dg_outputs[i]\n",
    "        dg_fre_output = dg_fre_outputs[i]\n",
    "        dg_fre_output = np.log(np.abs(dg_fre_output))/np.max(np.log(np.abs(dg_fre_output))) # log and normalize\n",
    "        axs[0,i].imshow(np.clip(np.transpose(dg_output, (1, 2, 0)),0,1)) # 转回int才可以直接imshow\n",
    "        axs[0,i].set_xlabel('After DG (image).')\n",
    "        axs[1,i].imshow(np.clip(np.transpose(dg_fre_output,(1,2,0)),0,1),cmap='gray')\n",
    "        axs[1,i].set_xlabel('After DG (frequency).')\n",
    "    plt.suptitle('Domain generalization example: {}.'.format(domain))\n",
    "    dg_outputs_domains.append(dg_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dis_rep import norm_dist,PSNR_metric,SSIM_metric,CS_dist,intra_cluster_distance,inter_cluster_diatance\n",
    "D_norm = np.zeros((3,3))\n",
    "D_CS = np.zeros((3,3))\n",
    "D_PSNR = np.zeros((3,3))\n",
    "D_SSIM = np.zeros((3,3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i == j:\n",
    "            D_norm[i,j] = intra_cluster_distance(dg_outputs_domains[i],distance_metric=norm_dist,ord=None)\n",
    "            D_CS[i,j] = intra_cluster_distance(dg_outputs_domains[i],distance_metric=CS_dist)\n",
    "            D_PSNR[i,j] = intra_cluster_distance(dg_outputs_domains[i],distance_metric=PSNR_metric)\n",
    "            D_SSIM[i,j] = intra_cluster_distance(dg_outputs_domains[i],distance_metric=SSIM_metric)\n",
    "        else:\n",
    "            D_norm[i,j] = inter_cluster_diatance(dg_outputs_domains[i],dg_outputs_domains[j],distance_type=2,distance_metric=norm_dist,ord=None)[0]\n",
    "            D_CS[i,j] = inter_cluster_diatance(dg_outputs_domains[i],dg_outputs_domains[j],distance_type=2,distance_metric=CS_dist)[0]\n",
    "            D_PSNR[i,j] = inter_cluster_diatance(dg_outputs_domains[i],dg_outputs_domains[j],distance_type=2,distance_metric=PSNR_metric)[0]\n",
    "            D_SSIM[i,j] = inter_cluster_diatance(dg_outputs_domains[i],dg_outputs_domains[j],distance_type=2,distance_metric=SSIM_metric)[0]\n",
    "print('Distances between 3 domains (norm):')\n",
    "print(D_norm)\n",
    "print('Distances between 3 domains (CS):')\n",
    "print(D_CS)\n",
    "print('Distances between 3 domains (PSNR):')\n",
    "print(D_PSNR)\n",
    "print('Distances between 3 domains (SSIM):')\n",
    "print(D_SSIM)\n",
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,0,:,:], rgb[:,1,:,:], rgb[:,2,:,:] # N * C * H * W\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "domain1_gray = rgb2gray(dg_outputs_domains[0])\n",
    "domain2_gray = rgb2gray(dg_outputs_domains[1])\n",
    "domain3_gray = rgb2gray(dg_outputs_domains[2])\n",
    "domain1_gray_average = np.mean(domain1_gray,axis=0)\n",
    "domain2_gray_average = np.mean(domain2_gray,axis=0)\n",
    "domain3_gray_average = np.mean(domain3_gray,axis=0)\n",
    "histogram1, bin_edges1 = np.histogram(domain1_gray_average, bins=256, range=(-0.5, 0.5))\n",
    "histogram2, bin_edges2 = np.histogram(domain2_gray_average, bins=256, range=(-0.5, 0.5))\n",
    "histogram3, bin_edges3 = np.histogram(domain3_gray_average, bins=256, range=(-0.5, 0.5))\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"Grayscale Histograms\")\n",
    "plt.xlabel(\"grayscale value\")\n",
    "plt.ylabel(\"pixel count\")\n",
    "plt.plot(bin_edges1[0:-1], histogram1,'r', bin_edges2[0:-1], histogram2, 'g', bin_edges3[0:-1], histogram3, 'b')\n",
    "plt.figlegend([\"domain1\",\"domain2\",\"domain3\"],loc='upper right')\n",
    "plt.grid(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib\n",
    "# We import seaborn to make nice plots.\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "domain_gray = np.concatenate((np.reshape(domain1_gray,(10,-1)),np.reshape(domain2_gray,(10,-1)),np.reshape(domain3_gray,(10,-1))),axis=0)\n",
    "domain_label = np.concatenate((np.ones(10),2*np.ones(10),3*np.ones(10)))\n",
    "original_image_gray = 0.2989 * original_image[0,:,:] + 0.5870 * original_image[1,:,:] + 0.1140 * original_image[0,:,:]\n",
    "original_image_gray = np.reshape(original_image_gray,(1,-1))\n",
    "X = np.concatenate((domain_gray,original_image_gray),axis=0)\n",
    "Y = np.concatenate((domain_label,np.zeros(1)),axis=0)\n",
    "digits_proj = TSNE(n_components=2,perplexity=3).fit_transform(X)\n",
    " \n",
    "def scatter(x, colors):\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "    f = plt.figure(figsize=(6, 6))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[colors.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    # ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "            txt = ax.text(xtext, ytext, \"original image\")\n",
    "        else:\n",
    "            xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "            txt = ax.text(xtext, ytext, \"domain\"+str(i), fontsize=24)\n",
    "            txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "scatter(digits_proj, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self,weight=None,size_average = True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "    def forward(self,inputs,targets,smooth=1):\n",
    "        inputs = F.sigmoid(inputs)\n",
    "        batch_number = targets.size(0)\n",
    "        # inputs = inputs[:,0,:,:]\n",
    "        Dice_BCE = 0\n",
    "        for i in range(2):\n",
    "            a = inputs[:,i].view(batch_number,-1)\n",
    "            b = targets[:,i].view(batch_number,-1)\n",
    "            intersection = (a*b).sum()\n",
    "            dice_loss = 1 - (2. * intersection + smooth) / (a.sum() + b.sum() + smooth)\n",
    "            Dice_BCE += dice_loss\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = Dice_BCE + BCE\n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "net = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "criterion = DiceBCELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "net = net.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self,weight=None,size_average = True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "    def forward(self,inputs,targets,smooth=1):\n",
    "        inputs = F.sigmoid(inputs)\n",
    "        batch_number = targets.size(0)\n",
    "        # inputs = inputs[:,0,:,:]\n",
    "        Dice_BCE = 0\n",
    "        for i in range(1):\n",
    "            a = inputs[:,i].view(batch_number,-1)\n",
    "            b = targets[:,i].view(batch_number,-1)\n",
    "            intersection = (a*b).sum()\n",
    "            dice_loss = 1 - (2. * intersection + smooth) / (a.sum() + b.sum() + smooth)\n",
    "            # print(dice_loss)\n",
    "            Dice_BCE += dice_loss\n",
    "        # Dice_BCE = Dice_BCE/2\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        # BCE = 0\n",
    "        Dice_BCE = Dice_BCE + BCE\n",
    "        return Dice_BCE\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import load_dataset\n",
    "import time\n",
    "\n",
    "epoch_number = 20\n",
    "\n",
    "for train_idx in [0]:\n",
    "    \"\"\"\n",
    "    Train idx = 0: No DG, No DA\n",
    "    Train idx = 1: DG, No DA\n",
    "    Train idx = 2: No DG, DA\n",
    "    Train idx = 3: DG, DA\n",
    "    Train idx = 4: training for domain 1\n",
    "    Train idx = 5: training for domain 2\n",
    "    Train idx = 6: training for domain 3\n",
    "    Train idx = 7: training for dynamic domain\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    #################### Model Define ######################\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    import segmentation_models_pytorch as smp\n",
    "    import torch\n",
    "\n",
    "    net = smp.Unet(\n",
    "        encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=2,                      # model output channels (number of classes in your dataset)\n",
    "    )\n",
    "\n",
    "    import torch.optim as optim\n",
    "    import torch.nn as nn\n",
    "\n",
    "\n",
    "    criterion = DiceBCELoss()\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    net = net.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    #################### Model Define ######################\n",
    "\n",
    "    if train_idx == 0:\n",
    "        ############# No DG #################\n",
    "        trainset, valset = load_dataset(train=True,is_vert_flip = False,is_rotate = False,is_translate = False,is_color_jitter = False,is_DG=0)\n",
    "        PATH = ('./results/model/net_no_DG_epoch_%d.pth') % (epoch_number)\n",
    "        log_file_name = ('./results/Loss/no_DG_epoch_%d.txt')%(epoch_number)\n",
    "        ############# No DG #################\n",
    "    elif train_idx == 1:\n",
    "        # ############## DG #################\n",
    "        trainset, valset = load_dataset(train=True,is_vert_flip = False,is_rotate = False,is_translate = False,is_color_jitter = False,is_DG=4)\n",
    "        PATH = ('./results/model/net_DG_epoch_%d.pth') % (epoch_number)\n",
    "        log_file_name = ('./results/Loss/DG_epoch_%d.txt')%(epoch_number)\n",
    "        # ############## DG #################\n",
    "    elif train_idx == 2:\n",
    "        ############## Data argument + No DG #################\n",
    "        trainset, valset = load_dataset(train=True,is_vert_flip = True,is_rotate = True,is_translate = True,is_color_jitter = True,is_DG=0)\n",
    "        PATH = ('./results/model/net_Data_arg_no_DG_epoch_%d.pth') % (epoch_number)\n",
    "        log_file_name = ('./results/Loss/Data_arg_no_DG_epoch_%d.txt')%(epoch_number)\n",
    "        ############## Data argument + No DG #################\n",
    "    elif train_idx == 3:\n",
    "        # ############ Data argument +  DG #################\n",
    "        trainset, valset = load_dataset(train=True,is_vert_flip = True,is_rotate = True,is_translate = True,is_color_jitter = True,is_DG=4)\n",
    "        PATH = ('./results/model/net_Data_arg_DG_epoch_%d.pth') % (epoch_number)\n",
    "        log_file_name = ('./results/Loss/Data_arg_DG_epoch_%d.txt')%(epoch_number)\n",
    "        # ############## Data argument +  DG #################\n",
    "    elif train_idx == 4:\n",
    "        # ############ Data argument +  DG + Domain 1 #################\n",
    "        trainset, valset = load_dataset(train=True,is_vert_flip = True,is_rotate = True,is_translate = True,is_color_jitter = False,is_DG=1)\n",
    "        PATH = ('./results/model/net_Data_arg_DG_D1_epoch_%d.pth') % (epoch_number)\n",
    "        log_file_name = ('./results/Loss/Data_arg_DG_D1_epoch_%d.txt')%(epoch_number)\n",
    "        # ############ Data argument +  DG + Domain 1 #################\n",
    "    elif train_idx == 5:\n",
    "        # ############ Data argument +  DG + Domain 2 #################\n",
    "        trainset, valset = load_dataset(train=True,is_vert_flip = True,is_rotate = True,is_translate = True,is_color_jitter = False,is_DG=2)\n",
    "        PATH = ('./results/model/net_Data_arg_DG_D2_epoch_%d.pth') % (epoch_number)\n",
    "        log_file_name = ('./results/Loss/Data_arg_DG_D2_epoch_%d.txt')%(epoch_number)\n",
    "        # ############ Data argument +  DG + Domain 2 #################\n",
    "    elif train_idx == 6:\n",
    "        # ############ Data argument +  DG + Domain 3 #################\n",
    "        trainset, valset = load_dataset(train=True,is_vert_flip = True,is_rotate = True,is_translate = True,is_color_jitter = False,is_DG=3)\n",
    "        PATH = ('./results/model/net_Data_arg_DG_D3_epoch_%d.pth') % (epoch_number)\n",
    "        log_file_name = ('./results/Loss/Data_arg_DG_D3_epoch_%d.txt')%(epoch_number)\n",
    "        # ############ Data argument +  DG + Domain 3 #################\n",
    "    elif train_idx == 7:\n",
    "        # ############ Data argument +  DG + Domain 1 #################\n",
    "        trainset, valset = load_dataset(train=True,is_vert_flip = False,is_rotate = False,is_translate = False,is_color_jitter = False,is_DG=1)\n",
    "        PATH = ('./results/model/net_DG_D1_epoch_%d.pth') % (epoch_number)\n",
    "        log_file_name = ('./results/Loss/Data_DG_D1_epoch_%d.txt')%(epoch_number)\n",
    "        # ############ Data argument +  DG + Domain 1 #################\n",
    "    else:\n",
    "        print(\"outof model bound\")\n",
    "        break\n",
    "    \n",
    "\n",
    "    log_file = open(log_file_name,'w')\n",
    "\n",
    "    ########### Delete file content\n",
    "    log_file.seek(0)\n",
    "    log_file.truncate()\n",
    "    ########### Delete file content\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = 4\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "    for epoch in range(epoch_number):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, target) in enumerate(trainloader):\n",
    "            \n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs,target)\n",
    "\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            log_file.write((\"%f\\n\") % loss.item())\n",
    "            # print((\"%f\\n\") % loss.item())\n",
    "            if i % 20 == 19:    # print every 20 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    log_file.close()\n",
    "    ################## Temp Model Save ##############\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "Note the validation set is highly related with the training set, therefore it is not wise to generate a new validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset, valset = load_dataset(train=True,is_vert_flip = False,is_rotate = False,is_translate = False,is_color_jitter = False,is_DG=0)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "import numpy as np\n",
    "dscs = []\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        # print(data)\n",
    "        (images, targets,names) = data\n",
    "        ############ Activate this for CUDA ##################\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        ############ Activate this for CUDA ##################\n",
    "        outputs = net(images.to(torch.float32))\n",
    "        \n",
    "        inputs = F.sigmoid(outputs)\n",
    "        batch_number = targets.size(0)\n",
    "        # inputs = inputs[:,0,:,:]\n",
    "        smooth = 1\n",
    "        Dice_BCE = 0\n",
    "        for j in range(2):\n",
    "            a = inputs[:,j].view(batch_number,-1)\n",
    "            b = targets[:,j].view(batch_number,-1)\n",
    "            intersection = (a*b).sum()\n",
    "            dice_loss = 1 - (2. * intersection + smooth) / (a.sum() + b.sum() + smooth)\n",
    "            Dice_BCE += dice_loss\n",
    "\n",
    "        dscs.append(1 - Dice_BCE.cpu().numpy()) \n",
    "dsc_test = np.mean(dscs)\n",
    "print(('Dsc of validation %f')% (dsc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.close()\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from dataset import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from medpy import metric\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "nclasses = 2\n",
    "epoch_number = 20\n",
    "############## No DG #################    \n",
    "# PATH = ('./results/model/net_no_DG_epoch_%d.pth') % (epoch_number)               # DICE loss model\n",
    "# PATH = ('./results/model/net_DG_epoch_%d.pth') % (epoch_number)                  # DG result \n",
    "# PATH = ('./results/model/net_Data_arg_no_DG_epoch_%d.pth') % (epoch_number)      # DA result     \n",
    "PATH = ('./results/model/net_Data_arg_DG_epoch_s03_r05_t%d.pth') % (epoch_number)  # DG + DA result\n",
    "# PATH = './results/model/net_no_DG_epoch_cross_entropy_20.pth'                      # Cross entropy loss result\n",
    "# PATH = ('./results/model/net_no_DG_epoch_DICE_t%d.pth') % (epoch_number)         # Dice Loss result\n",
    "############## No DG #################\n",
    "\n",
    "############## Metric Type ################\n",
    "# metric_type = \"DICE\"\n",
    "metric_type = \"HD95\"\n",
    "# metric_type = \"TA\"\n",
    "############## Metric Type ################\n",
    "\n",
    "net = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=nclasses,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net.load_state_dict(torch.load(PATH,map_location='cpu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    # Contruct test loader for different test region\n",
    "    test_data_str = (\"./data/Pro1-SegmentationData/Domain%d/data/*.bmp\") % (i + 1)\n",
    "    test_label_str = (\"./data/Pro1-SegmentationData/Domain%d/label/{}.bmp\") % (i + 1)\n",
    "    if i == 0:\n",
    "        test_data_str = (\"./data/Pro1-SegmentationData/Domain%d/data/*.jpg\") % (i + 1)\n",
    "        test_label_str = (\"./data/Pro1-SegmentationData/Domain%d/label/{}.png\") % (i + 1)\n",
    "    testset = load_dataset(train=False,test_data_str = test_data_str, test_label_str = test_label_str)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "    dscs = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, targets, names = data\n",
    "            ############ Activate this for CUDA ##################\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            ############ Activate this for CUDA ##################\n",
    "            outputs = net(images.to(torch.float32))\n",
    "            \n",
    "            if metric_type == \"DICE\":\n",
    "                ############ DICE metric #############################\n",
    "                inputs = F.sigmoid(outputs)\n",
    "                batch_number = targets.size(0)\n",
    "                # inputs = inputs[:,0,:,:]\n",
    "                smooth = 1\n",
    "                Dice_BCE = 0\n",
    "                for j in range(2):\n",
    "                    a = inputs[:,j].view(batch_number,-1)\n",
    "                    b = targets[:,j].view(batch_number,-1)\n",
    "                    intersection = (a*b).sum()\n",
    "                    dice_loss = 1 - (2. * intersection + smooth) / (a.sum() + b.sum() + smooth)\n",
    "                    Dice_BCE += dice_loss\n",
    "\n",
    "                dscs.append(1 - Dice_BCE.cpu().numpy()) \n",
    "                ############ DICE metric #############################\n",
    "            elif metric_type ==  \"HD95\":\n",
    "                ############ HD 95 metric ############################\n",
    "                for idx, name in enumerate(names):\n",
    "                    output_np = torch.argmax(outputs[idx], dim=0).cpu().numpy()\n",
    "                    binary_output = np.array(output_np)\n",
    "                    target_np = torch.argmax(targets[idx], dim=0).cpu().numpy()\n",
    "                    # target_1d = np.reshape(target_np, (-1, 1))\n",
    "                    # pred_1d = np.reshape(binary_output, (-1, 1))\n",
    "                    # plt.imshow(output_np,cmap='gray')\n",
    "                    # plt.show()\n",
    "                    # dsc = max(directed_hausdorff(output_np,target_np)[0],directed_hausdorff(target_np,output_np)[0])\n",
    "                    dsc = metric.binary.hd95(target_np,output_np)\n",
    "                    dscs.append(dsc) \n",
    "                ############ HD 95 metric ############################\n",
    "            elif metric_type ==  \"TA\":\n",
    "                ########### Dice by TA ##############################\n",
    "                for idx, name in enumerate(names):\n",
    "                    output_np = torch.argmax(outputs[idx], dim=0).cpu().numpy()\n",
    "                    binary_output = np.array(output_np)\n",
    "                    target_np = torch.argmax(targets[idx], dim=0).cpu().numpy()\n",
    "                    target_1d = np.reshape(target_np, (-1, 1))\n",
    "                    pred_1d = np.reshape(binary_output, (-1, 1))\n",
    "                    # plt.imshow(output_np,cmap='gray')\n",
    "                    # plt.show()\n",
    "                    accuracy = accuracy_score(target_1d, pred_1d)\n",
    "                    # print(accuracy)\n",
    "                    if nclasses == 2:\n",
    "                        dsc = f1_score(target_1d, pred_1d) # f1_score就是Dice\n",
    "                    else:\n",
    "                        dsc = f1_score(target_1d, pred_1d,average='micro')\n",
    "                    dscs.append(dsc) \n",
    "                ########### Dice by TA ##############################\n",
    "            else:\n",
    "                print((\"Not a valid/implemented metric %s\") % metric_type)\n",
    "                break\n",
    "            \n",
    "    dsc_test = np.mean(dscs)\n",
    "    print(('Dsc of test set %d: %f')% (i + 1,dsc_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show last predicted result\n",
    "import matplotlib.pyplot as plt\n",
    "for i,_ in enumerate(images):\n",
    "    image = images.cpu().numpy()[i]\n",
    "    target_np = torch.argmax(targets[i], dim=0).cpu().numpy()\n",
    "    output_np = torch.argmax(outputs[i], dim=0).cpu().numpy()\n",
    "    image = image/2 + 0.5\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(np.transpose(image,(1,2,0)))\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(target_np,cmap='gray')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(output_np,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff00b26d6b990ba17d2f20ddcdd7d48aa18f7559c6b1d8ae74680a301a112ff1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
