{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo for project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset import load_dataset\n",
    "\n",
    "trainset, valset = load_dataset(train=True,is_vert_flip = False,is_rotate = True,is_translate = True,is_color_jitter = False,is_DG=False)\n",
    "testset = load_dataset(train=False)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    # The data need to be normalized and unnormalized to keep the same\n",
    "    # img = img / 255\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, targets = next(dataiter)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print(names)\n",
    "for i in range(batch_size):\n",
    "    target = targets.numpy()[i,:,:]\n",
    "    plt.subplot(1,batch_size,i+1)\n",
    "    plt.imshow(target,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Domain generalization example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import domain_generization, load_dataset\n",
    "trainset_temp, _ = load_dataset(train=True,is_vert_flip = True,is_rotate = True,is_translate = True,is_color_jitter = False,is_DG=True)\n",
    "# trainset_temp, _ = load_dataset(train=True,is_vert_flip = False,is_rotate = False,is_translate = False,is_color_jitter = False,is_DG=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "original_image, _ = trainset_temp.__getitem__(5) # Use the first image in training set.\n",
    "original_image = original_image / 2 + 0.5\n",
    "original_image = original_image.numpy()\n",
    "scaling_factor = 0.01 # 替换低频区域所占大小\n",
    "ratio = 1 #替换区域中目标域图片的幅度比重 \n",
    "num_generalized=10\n",
    "domains = ['domain1','domain2','domain3'] # 可选：'random'（默认随机选择domain）, 'domain1', 'domain2', 'domain3'.\n",
    "original_image_freq = np.fft.fftshift(np.fft.fft2(original_image,axes=(-2,-1)),axes=(-2,-1))\n",
    "original_image_freq = np.log(np.abs(original_image_freq))/np.max(np.log(np.abs(original_image_freq))) # log and normalize\n",
    "plt.figure(figsize=[4,2])\n",
    "plt.subplot(1,2,1), plt.imshow(np.transpose(original_image, (1, 2, 0))), plt.xlabel('Raw Image.')\n",
    "plt.subplot(1,2,2), plt.imshow(np.transpose(original_image_freq, (1, 2, 0))), plt.xlabel('Raw Image (frequency).')\n",
    "dg_outputs_domains = []\n",
    "for domain in domains:\n",
    "    dg_outputs, dg_fre_outputs= np.array(domain_generization(original_image,scaling_factor, ratio,num_generalized,domain)) # 输出是一个float, 因为计算傅里叶变换的时候应该用float提高精度\n",
    "    fig, axs = plt.subplots(2, num_generalized, figsize=(2*num_generalized, 2*2), layout=\"constrained\")\n",
    "    for i in range(num_generalized):\n",
    "        dg_output = np.real(dg_outputs[i])\n",
    "        dg_fre_output = dg_fre_outputs[i]\n",
    "        dg_fre_output = np.log(np.abs(dg_fre_output))/np.max(np.log(np.abs(dg_fre_output))) # log and normalize\n",
    "        axs[0,i].imshow(np.clip(np.transpose(dg_output, (1, 2, 0)),0,1)) # 转回int才可以直接imshow\n",
    "        axs[0,i].set_xlabel('After DG (image).')\n",
    "        axs[1,i].imshow(np.clip(np.transpose(dg_fre_output,(1,2,0)),0,1),cmap='gray')\n",
    "        axs[1,i].set_xlabel('After DG (frequency).')\n",
    "    plt.suptitle('Domain generalization example: {}.'.format(domain))\n",
    "    dg_outputs_domains.append(dg_outputs)\n",
    "dg_outputs = np.asarray(dg_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dis_rep import norm_dist,CS_dist,intra_cluster_distance,inter_cluster_diatance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "net = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, target) in enumerate(trainloader):\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimizeo \n",
    "        # change the data to float type\n",
    "        outputs = net(inputs)\n",
    "        # outputs = torch.argmax(outputs, dim=1)\n",
    "        # print((outputs.shape))\n",
    "        # print(target.to(torch.float32).dtype)\n",
    "        \n",
    "        loss = criterion(outputs,target.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show last valiadated result\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "input = inputs.numpy()[-1]\n",
    "input = input/2 + 0.5\n",
    "output_np = torch.argmax(outputs[-1], dim=0).cpu().numpy()\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(np.transpose(input,(1,2,0)))\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(target[-1,:,:],cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(output_np,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "nclasses = 2\n",
    "\n",
    "net = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=nclasses,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "\n",
    "net.load_state_dict(torch.load(PATH,map_location='cpu'))\n",
    "dscs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, targets, names = data\n",
    "        \n",
    "        outputs = net(images.to(torch.float32))\n",
    "        \n",
    "        for idx, name in enumerate(names):\n",
    "            output_np = torch.argmax(outputs[idx], dim=0).cpu().numpy()\n",
    "            binary_output = np.array(output_np)\n",
    "            target_np = targets[idx].cpu().numpy().astype(np.uint8)\n",
    "            \n",
    "            target_1d = np.reshape(target_np, (-1, 1))\n",
    "            pred_1d = np.reshape(binary_output, (-1, 1))\n",
    "            accuracy = accuracy_score(target_1d, pred_1d)\n",
    "            if nclasses == 2:\n",
    "                dsc = f1_score(target_1d, pred_1d)\n",
    "            else:\n",
    "                dsc = f1_score(target_1d, pred_1d,average='micro')\n",
    "            dscs.append(dsc)\n",
    "\n",
    "dsc_test = np.mean(dscs)\n",
    "print('Dsc of test set:', dsc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show last predicted result\n",
    "import matplotlib.pyplot as plt\n",
    "image = images.numpy()[-1]\n",
    "output = outputs.numpy()[-1,:,:,:]\n",
    "output = output/2 + 0.5\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(np.transpose(image,(1,2,0)))\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(target_np,cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(binary_output,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1b9c7f2f57af8f07e064f2c72ed76cd3499c7b2fb82bb3d901b6e74555bba53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
